{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you like the kernel, consider upvoting it and the associated datasets:\n",
    "\n",
    "https://www.kaggle.com/abhishek/transformers\n",
    "\n",
    "https://www.kaggle.com/abhishek/sacremoses\n",
    "\n",
    "https://www.kaggle.com/abhishek/distilbertbaseuncased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most of the code in this kernel comes directly from:\n",
    "\n",
    "https://www.kaggle.com/abazdyrev/use-features-oof\n",
    "\n",
    "Please consider upvoting it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../input/sacremoses/sacremoses-master/ > /dev/null\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, \"../input/transformers/transformers-master/\")\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_vectors(string_list, batch_size=64):\n",
    "    # inspired by https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    tokenizer = transformers.DistilBertTokenizer.from_pretrained(\"../input/distilbertbaseuncased/\")\n",
    "    model = transformers.DistilBertModel.from_pretrained(\"../input/distilbertbaseuncased/\")\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    fin_features = []\n",
    "    for data in chunks(string_list, batch_size):\n",
    "        tokenized = []\n",
    "        for x in data:\n",
    "            x = \" \".join(x.strip().split()[:300])\n",
    "            tok = tokenizer.encode(x, add_special_tokens=True)\n",
    "            tokenized.append(tok[:512])\n",
    "\n",
    "        max_len = 512\n",
    "        padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized])\n",
    "        attention_mask = np.where(padded != 0, 1, 0)\n",
    "        input_ids = torch.tensor(padded).to(DEVICE)\n",
    "        attention_mask = torch.tensor(attention_mask).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        features = last_hidden_states[0][:, 0, :].cpu().numpy()\n",
    "        fin_features.append(features)\n",
    "\n",
    "    fin_features = np.vstack(fin_features)\n",
    "    return fin_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/google-quest-challenge/train.csv\").fillna(\"none\")\n",
    "df_test = pd.read_csv(\"../input/google-quest-challenge/test.csv\").fillna(\"none\")\n",
    "\n",
    "sample = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\")\n",
    "target_cols = list(sample.drop(\"qa_id\", axis=1).columns)\n",
    "\n",
    "train_question_body_dense = fetch_vectors(df_train.question_body.values)\n",
    "train_answer_dense = fetch_vectors(df_train.answer.values)\n",
    "\n",
    "test_question_body_dense = fetch_vectors(df_test.question_body.values)\n",
    "test_answer_dense = fetch_vectors(df_test.answer.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import pickle  \n",
    "import random\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "from os.path import join as path_join\n",
    "from numpy.random import seed\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "\n",
    "seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6079, 41) (476, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0      0  What am I losing when using extension tubes in...   \n",
       "1      1  What is the distinction between a city and a s...   \n",
       "2      2  Maximum protusion length for through-hole comp...   \n",
       "3      3              Can an affidavit be used in Beit Din?   \n",
       "4      5       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  After playing around with macro photography on...               ysap   \n",
       "1  I am trying to understand what kinds of places...      russellpierce   \n",
       "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4  I am trying to make a binary image. I want mor...            leigero   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1024   \n",
       "1           https://rpg.stackexchange.com/users/8774   \n",
       "2  https://electronics.stackexchange.com/users/10157   \n",
       "3       https://judaism.stackexchange.com/users/5151   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  I just got extension tubes, so here's the skin...           rfusca   \n",
       "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
       "\n",
       "                                    answer_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1917   \n",
       "1           https://rpg.stackexchange.com/users/1871   \n",
       "2  https://electronics.stackexchange.com/users/64754   \n",
       "3       https://judaism.stackexchange.com/users/4794   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                                 url   category  ...  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n",
       "2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n",
       "3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n",
       "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n",
       "\n",
       "  question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0              1.000000        1.000000                     0.666667   \n",
       "1              0.888889        0.888889                     0.555556   \n",
       "2              0.777778        0.777778                     0.555556   \n",
       "3              0.888889        0.833333                     0.333333   \n",
       "4              1.000000        1.000000                     0.666667   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          1.000000          1.000000             0.800000   \n",
       "1          0.888889          0.888889             0.666667   \n",
       "2          1.000000          1.000000             0.666667   \n",
       "3          0.833333          1.000000             0.800000   \n",
       "4          1.000000          1.000000             0.800000   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                       1.0               0.000000   \n",
       "1                       0.0               0.000000   \n",
       "2                       0.0               0.333333   \n",
       "3                       0.0               0.000000   \n",
       "4                       1.0               0.000000   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.000000             1.000000  \n",
       "1                        0.666667             0.888889  \n",
       "2                        1.000000             0.888889  \n",
       "3                        1.000000             1.000000  \n",
       "4                        1.000000             1.000000  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../input/google-quest-challenge/'\n",
    "train = pd.read_csv(path_join(data_dir, 'train.csv'))\n",
    "test = pd.read_csv(path_join(data_dir, 'test.csv'))\n",
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "        'question_asker_intent_understanding',\n",
    "        'question_body_critical',\n",
    "        'question_conversational',\n",
    "        'question_expect_short_answer',\n",
    "        'question_fact_seeking',\n",
    "        'question_has_commonly_accepted_answer',\n",
    "        'question_interestingness_others',\n",
    "        'question_interestingness_self',\n",
    "        'question_multi_intent',\n",
    "        'question_not_really_a_question',\n",
    "        'question_opinion_seeking',\n",
    "        'question_type_choice',\n",
    "        'question_type_compare',\n",
    "        'question_type_consequence',\n",
    "        'question_type_definition',\n",
    "        'question_type_entity',\n",
    "        'question_type_instructions',\n",
    "        'question_type_procedure',\n",
    "        'question_type_reason_explanation',\n",
    "        'question_type_spelling',\n",
    "        'question_well_written',\n",
    "        'answer_helpful',\n",
    "        'answer_level_of_information',\n",
    "        'answer_plausible',\n",
    "        'answer_relevance',\n",
    "        'answer_satisfaction',\n",
    "        'answer_type_instructions',\n",
    "        'answer_type_procedure',\n",
    "        'answer_type_reason_explanation',\n",
    "        'answer_well_written'    \n",
    "    ]\n",
    "\n",
    "input_columns = ['question_title', 'question_body', 'answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = re.compile(r\"^[^.]*\")\n",
    "\n",
    "train['netloc'] = train['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n",
    "test['netloc'] = test['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n",
    "\n",
    "features = ['netloc', 'category']\n",
    "merged = pd.concat([train[features], test[features]])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(merged)\n",
    "\n",
    "features_train = ohe.transform(train[features]).toarray()\n",
    "features_test = ohe.transform(test[features]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"../input/universalsentenceencoderlarge4/\"\n",
    "embed = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_title\n",
      "question_body\n",
      "answer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train = {}\n",
    "embeddings_test = {}\n",
    "for text in input_columns:\n",
    "    print(text)\n",
    "    train_text = train[text].str.replace('?', '.').str.replace('!', '.').tolist()\n",
    "    test_text = test[text].str.replace('?', '.').str.replace('!', '.').tolist()\n",
    "    \n",
    "    curr_train_emb = []\n",
    "    curr_test_emb = []\n",
    "    batch_size = 4\n",
    "    ind = 0\n",
    "    while ind*batch_size < len(train_text):\n",
    "        curr_train_emb.append(embed(train_text[ind*batch_size: (ind + 1)*batch_size])[\"outputs\"].numpy())\n",
    "        ind += 1\n",
    "        \n",
    "    ind = 0\n",
    "    while ind*batch_size < len(test_text):\n",
    "        curr_test_emb.append(embed(test_text[ind*batch_size: (ind + 1)*batch_size])[\"outputs\"].numpy())\n",
    "        ind += 1    \n",
    "        \n",
    "    embeddings_train[text + '_embedding'] = np.vstack(curr_train_emb)\n",
    "    embeddings_test[text + '_embedding'] = np.vstack(curr_test_emb)\n",
    "    \n",
    "del embed\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dist = lambda x, y: np.power(x - y, 2).sum(axis=1)\n",
    "\n",
    "cos_dist = lambda x, y: (x*y).sum(axis=1)\n",
    "\n",
    "dist_features_train = np.array([\n",
    "    l2_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),\n",
    "    l2_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),\n",
    "    l2_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding']),\n",
    "    cos_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),\n",
    "    cos_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),\n",
    "    cos_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding'])\n",
    "]).T\n",
    "\n",
    "dist_features_test = np.array([\n",
    "    l2_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),\n",
    "    l2_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),\n",
    "    l2_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding']),\n",
    "    cos_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),\n",
    "    cos_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),\n",
    "    cos_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding'])\n",
    "]).T\n",
    "\n",
    "X_train = np.hstack([item for k, item in embeddings_train.items()] + [features_train, dist_features_train])\n",
    "X_test = np.hstack([item for k, item in embeddings_test.items()] + [features_test, dist_features_test])\n",
    "y_train = train[targets].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack((X_train, train_question_body_dense, train_answer_dense))\n",
    "X_test = np.hstack((X_test, test_question_body_dense, test_answer_dense))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatible with tensorflow backend\n",
    "class SpearmanRhoCallback(Callback):\n",
    "    def __init__(self, training_data, validation_data, patience, model_name):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.value = -1\n",
    "        self.bad_epochs = 0\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        rho_val = np.mean([spearmanr(self.y_val[:, ind], y_pred_val[:, ind] + np.random.normal(0, 1e-7, y_pred_val.shape[0])).correlation for ind in range(y_pred_val.shape[1])])\n",
    "        if rho_val >= self.value:\n",
    "            self.value = rho_val\n",
    "        else:\n",
    "            self.bad_epochs += 1\n",
    "        if self.bad_epochs >= self.patience:\n",
    "            print(\"Epoch %05d: early stopping Threshold\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "            #self.model.save_weights(self.model_name)\n",
    "        print('\\rval_spearman-rho: %s' % (str(round(rho_val, 4))), end=100*' '+'\\n')\n",
    "        return rho_val\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inps = Input(shape=(X_train.shape[1],))\n",
    "    x = Dense(512, activation='elu')(inps)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(y_train.shape[1], activation='sigmoid')(x)\n",
    "    model = Model(inputs=inps, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=1e-4),\n",
    "        loss=['binary_crossentropy']\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3142)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1609216   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 1,624,606\n",
      "Trainable params: 1,624,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 159us/step - loss: 0.4249 - val_loss: 0.3980\n",
      "val_spearman-rho: 0.2817                                                                                                    \n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3955 - val_loss: 0.3890\n",
      "val_spearman-rho: 0.3228                                                                                                    \n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 124us/step - loss: 0.3872 - val_loss: 0.3847\n",
      "val_spearman-rho: 0.3441                                                                                                    \n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3814 - val_loss: 0.3828\n",
      "val_spearman-rho: 0.3567                                                                                                    \n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3776 - val_loss: 0.3792\n",
      "val_spearman-rho: 0.3648                                                                                                    \n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3738 - val_loss: 0.3779\n",
      "val_spearman-rho: 0.3712                                                                                                    \n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3704 - val_loss: 0.3766\n",
      "val_spearman-rho: 0.3735                                                                                                    \n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3681 - val_loss: 0.3758\n",
      "val_spearman-rho: 0.3785                                                                                                    \n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3656 - val_loss: 0.3748\n",
      "val_spearman-rho: 0.3801                                                                                                    \n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3635 - val_loss: 0.3736\n",
      "val_spearman-rho: 0.3826                                                                                                    \n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3615 - val_loss: 0.3722\n",
      "val_spearman-rho: 0.3835                                                                                                    \n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3595 - val_loss: 0.3724\n",
      "val_spearman-rho: 0.3842                                                                                                    \n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 124us/step - loss: 0.3580 - val_loss: 0.3717\n",
      "val_spearman-rho: 0.3841                                                                                                    \n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3566 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3857                                                                                                    \n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3550 - val_loss: 0.3733\n",
      "val_spearman-rho: 0.3842                                                                                                    \n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3537 - val_loss: 0.3709\n",
      "val_spearman-rho: 0.3865                                                                                                    \n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3524 - val_loss: 0.3714\n",
      "val_spearman-rho: 0.3859                                                                                                    \n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3510 - val_loss: 0.3721\n",
      "val_spearman-rho: 0.3865                                                                                                    \n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3500 - val_loss: 0.3713\n",
      "val_spearman-rho: 0.3849                                                                                                    \n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3494 - val_loss: 0.3726\n",
      "Epoch 00019: early stopping Threshold\n",
      "val_spearman-rho: 0.3849                                                                                                    \n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3142)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1609216   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 1,624,606\n",
      "Trainable params: 1,624,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 162us/step - loss: 0.4269 - val_loss: 0.3963\n",
      "val_spearman-rho: 0.2775                                                                                                    \n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3959 - val_loss: 0.3887\n",
      "val_spearman-rho: 0.3184                                                                                                    \n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3877 - val_loss: 0.3835\n",
      "val_spearman-rho: 0.3416                                                                                                    \n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3819 - val_loss: 0.3806\n",
      "val_spearman-rho: 0.354                                                                                                    \n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3780 - val_loss: 0.3783\n",
      "val_spearman-rho: 0.3641                                                                                                    \n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3740 - val_loss: 0.3768\n",
      "val_spearman-rho: 0.3699                                                                                                    \n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3710 - val_loss: 0.3761\n",
      "val_spearman-rho: 0.3743                                                                                                    \n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3682 - val_loss: 0.3741\n",
      "val_spearman-rho: 0.3794                                                                                                    \n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3662 - val_loss: 0.3739\n",
      "val_spearman-rho: 0.3821                                                                                                    \n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3637 - val_loss: 0.3726\n",
      "val_spearman-rho: 0.385                                                                                                    \n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3621 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3867                                                                                                    \n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3599 - val_loss: 0.3712\n",
      "val_spearman-rho: 0.3883                                                                                                    \n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3584 - val_loss: 0.3716\n",
      "val_spearman-rho: 0.3867                                                                                                    \n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 1s 124us/step - loss: 0.3569 - val_loss: 0.3709\n",
      "val_spearman-rho: 0.3901                                                                                                    \n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3554 - val_loss: 0.3712\n",
      "val_spearman-rho: 0.3886                                                                                                    \n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3540 - val_loss: 0.3718\n",
      "val_spearman-rho: 0.3897                                                                                                    \n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3527 - val_loss: 0.3716\n",
      "val_spearman-rho: 0.3903                                                                                                    \n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3517 - val_loss: 0.3706\n",
      "val_spearman-rho: 0.3912                                                                                                    \n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3503 - val_loss: 0.3705\n",
      "val_spearman-rho: 0.391                                                                                                    \n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3495 - val_loss: 0.3713\n",
      "Epoch 00019: early stopping Threshold\n",
      "val_spearman-rho: 0.3891                                                                                                    \n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3142)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1609216   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 1,624,606\n",
      "Trainable params: 1,624,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 165us/step - loss: 0.4235 - val_loss: 0.3967\n",
      "val_spearman-rho: 0.2853                                                                                                    \n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 130us/step - loss: 0.3947 - val_loss: 0.3887\n",
      "val_spearman-rho: 0.3253                                                                                                    \n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3866 - val_loss: 0.3839\n",
      "val_spearman-rho: 0.3416                                                                                                    \n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3810 - val_loss: 0.3817\n",
      "val_spearman-rho: 0.3526                                                                                                    \n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 130us/step - loss: 0.3770 - val_loss: 0.3805\n",
      "val_spearman-rho: 0.3592                                                                                                    \n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 1s 130us/step - loss: 0.3736 - val_loss: 0.3780\n",
      "val_spearman-rho: 0.3645                                                                                                    \n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3701 - val_loss: 0.3777\n",
      "val_spearman-rho: 0.3684                                                                                                    \n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 129us/step - loss: 0.3677 - val_loss: 0.3752\n",
      "val_spearman-rho: 0.3727                                                                                                    \n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3655 - val_loss: 0.3743\n",
      "val_spearman-rho: 0.3755                                                                                                    \n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3631 - val_loss: 0.3735\n",
      "val_spearman-rho: 0.379                                                                                                    \n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.3615 - val_loss: 0.3730\n",
      "val_spearman-rho: 0.3796                                                                                                    \n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3600 - val_loss: 0.3730\n",
      "val_spearman-rho: 0.3809                                                                                                    \n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3579 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3825                                                                                                    \n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3564 - val_loss: 0.3722\n",
      "val_spearman-rho: 0.3828                                                                                                    \n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3547 - val_loss: 0.3717\n",
      "val_spearman-rho: 0.3834                                                                                                    \n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3537 - val_loss: 0.3710\n",
      "val_spearman-rho: 0.3853                                                                                                    \n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3522 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3843                                                                                                    \n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3511 - val_loss: 0.3715\n",
      "val_spearman-rho: 0.3863                                                                                                    \n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3502 - val_loss: 0.3721\n",
      "val_spearman-rho: 0.3847                                                                                                    \n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 131us/step - loss: 0.3489 - val_loss: 0.3720\n",
      "val_spearman-rho: 0.3852                                                                                                    \n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 1s 127us/step - loss: 0.3478 - val_loss: 0.3715\n",
      "val_spearman-rho: 0.3857                                                                                                    \n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3470 - val_loss: 0.3715\n",
      "Epoch 00021: early stopping Threshold\n",
      "val_spearman-rho: 0.3848                                                                                                    \n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3142)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               1609216   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 1,624,606\n",
      "Trainable params: 1,624,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 156us/step - loss: 0.4230 - val_loss: 0.3944\n",
      "val_spearman-rho: 0.2756                                                                                                    \n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3954 - val_loss: 0.3872\n",
      "val_spearman-rho: 0.3165                                                                                                    \n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3871 - val_loss: 0.3830\n",
      "val_spearman-rho: 0.3349                                                                                                    \n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3814 - val_loss: 0.3800\n",
      "val_spearman-rho: 0.3464                                                                                                    \n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3771 - val_loss: 0.3778\n",
      "val_spearman-rho: 0.3569                                                                                                    \n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3733 - val_loss: 0.3772\n",
      "val_spearman-rho: 0.3626                                                                                                    \n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3702 - val_loss: 0.3748\n",
      "val_spearman-rho: 0.3671                                                                                                    \n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3677 - val_loss: 0.3743\n",
      "val_spearman-rho: 0.3712                                                                                                    \n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3652 - val_loss: 0.3733\n",
      "val_spearman-rho: 0.3742                                                                                                    \n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3632 - val_loss: 0.3734\n",
      "val_spearman-rho: 0.3772                                                                                                    \n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3613 - val_loss: 0.3720\n",
      "val_spearman-rho: 0.3785                                                                                                    \n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 124us/step - loss: 0.3596 - val_loss: 0.3718\n",
      "val_spearman-rho: 0.3792                                                                                                    \n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3582 - val_loss: 0.3736\n",
      "val_spearman-rho: 0.3799                                                                                                    \n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3567 - val_loss: 0.3707\n",
      "val_spearman-rho: 0.3807                                                                                                    \n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3549 - val_loss: 0.3722\n",
      "val_spearman-rho: 0.3803                                                                                                    \n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3535 - val_loss: 0.3713\n",
      "val_spearman-rho: 0.3818                                                                                                    \n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3524 - val_loss: 0.3712\n",
      "val_spearman-rho: 0.3815                                                                                                    \n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3516 - val_loss: 0.3713\n",
      "val_spearman-rho: 0.3821                                                                                                    \n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3500 - val_loss: 0.3703\n",
      "val_spearman-rho: 0.3829                                                                                                    \n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3489 - val_loss: 0.3711\n",
      "val_spearman-rho: 0.3832                                                                                                    \n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3479 - val_loss: 0.3708\n",
      "val_spearman-rho: 0.3824                                                                                                    \n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3472 - val_loss: 0.3702\n",
      "val_spearman-rho: 0.3824                                                                                                    \n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3458 - val_loss: 0.3703\n",
      "Epoch 00022: early stopping Threshold\n",
      "val_spearman-rho: 0.3821                                                                                                    \n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3142)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               1609216   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 1,624,606\n",
      "Trainable params: 1,624,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4864 samples, validate on 1215 samples\n",
      "Epoch 1/100\n",
      "4864/4864 [==============================] - 1s 158us/step - loss: 0.4257 - val_loss: 0.3944\n",
      "val_spearman-rho: 0.2828                                                                                                    \n",
      "Epoch 2/100\n",
      "4864/4864 [==============================] - 1s 124us/step - loss: 0.3956 - val_loss: 0.3874\n",
      "val_spearman-rho: 0.3207                                                                                                    \n",
      "Epoch 3/100\n",
      "4864/4864 [==============================] - 1s 128us/step - loss: 0.3874 - val_loss: 0.3835\n",
      "val_spearman-rho: 0.3408                                                                                                    \n",
      "Epoch 4/100\n",
      "4864/4864 [==============================] - 1s 126us/step - loss: 0.3816 - val_loss: 0.3806\n",
      "val_spearman-rho: 0.3528                                                                                                    \n",
      "Epoch 5/100\n",
      "4864/4864 [==============================] - 1s 124us/step - loss: 0.3772 - val_loss: 0.3786\n",
      "val_spearman-rho: 0.36                                                                                                    \n",
      "Epoch 6/100\n",
      "4864/4864 [==============================] - 1s 129us/step - loss: 0.3733 - val_loss: 0.3773\n",
      "val_spearman-rho: 0.3645                                                                                                    \n",
      "Epoch 7/100\n",
      "4864/4864 [==============================] - 1s 126us/step - loss: 0.3701 - val_loss: 0.3764\n",
      "val_spearman-rho: 0.368                                                                                                    \n",
      "Epoch 8/100\n",
      "4864/4864 [==============================] - 1s 127us/step - loss: 0.3681 - val_loss: 0.3753\n",
      "val_spearman-rho: 0.3724                                                                                                    \n",
      "Epoch 9/100\n",
      "4864/4864 [==============================] - 1s 127us/step - loss: 0.3650 - val_loss: 0.3753\n",
      "val_spearman-rho: 0.3739                                                                                                    \n",
      "Epoch 10/100\n",
      "4864/4864 [==============================] - 1s 129us/step - loss: 0.3628 - val_loss: 0.3748\n",
      "val_spearman-rho: 0.3763                                                                                                    \n",
      "Epoch 11/100\n",
      "4864/4864 [==============================] - 1s 125us/step - loss: 0.3611 - val_loss: 0.3744\n",
      "val_spearman-rho: 0.3781                                                                                                    \n",
      "Epoch 12/100\n",
      "4864/4864 [==============================] - 1s 126us/step - loss: 0.3592 - val_loss: 0.3730\n",
      "val_spearman-rho: 0.3795                                                                                                    \n",
      "Epoch 13/100\n",
      "4864/4864 [==============================] - 1s 122us/step - loss: 0.3575 - val_loss: 0.3738\n",
      "val_spearman-rho: 0.3782                                                                                                    \n",
      "Epoch 14/100\n",
      "4864/4864 [==============================] - 1s 125us/step - loss: 0.3562 - val_loss: 0.3730\n",
      "val_spearman-rho: 0.3806                                                                                                    \n",
      "Epoch 15/100\n",
      "4864/4864 [==============================] - 1s 125us/step - loss: 0.3547 - val_loss: 0.3739\n",
      "val_spearman-rho: 0.3801                                                                                                    \n",
      "Epoch 16/100\n",
      "4864/4864 [==============================] - 1s 128us/step - loss: 0.3531 - val_loss: 0.3730\n",
      "val_spearman-rho: 0.3809                                                                                                    \n",
      "Epoch 17/100\n",
      "4864/4864 [==============================] - 1s 124us/step - loss: 0.3518 - val_loss: 0.3728\n",
      "val_spearman-rho: 0.3805                                                                                                    \n",
      "Epoch 18/100\n",
      "4864/4864 [==============================] - 1s 126us/step - loss: 0.3512 - val_loss: 0.3729\n",
      "val_spearman-rho: 0.3799                                                                                                    \n",
      "Epoch 19/100\n",
      "4864/4864 [==============================] - 1s 125us/step - loss: 0.3501 - val_loss: 0.3743\n",
      "Epoch 00018: early stopping Threshold\n",
      "val_spearman-rho: 0.3791                                                                                                    \n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 3142)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               1609216   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 1,624,606\n",
      "Trainable params: 1,624,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1803: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 73.51509188631007, tolerance: 0.8890928173433562\n",
      "  check_random_state(self.random_state), random)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1803: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.99423221016332, tolerance: 0.8902148281023502\n",
      "  check_random_state(self.random_state), random)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1803: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 85.6621479397445, tolerance: 0.898013530452929\n",
      "  check_random_state(self.random_state), random)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1803: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.44103130078838, tolerance: 0.8963124509333517\n",
      "  check_random_state(self.random_state), random)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1803: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 112.68660790174044, tolerance: 0.8919041259695826\n",
      "  check_random_state(self.random_state), random)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1803: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.69277570623308, tolerance: 1.1164365005777837\n",
      "  check_random_state(self.random_state), random)\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for ind, (tr, val) in enumerate(kf.split(X_train)):\n",
    "    X_tr = X_train[tr]\n",
    "    y_tr = y_train[tr]\n",
    "    X_vl = X_train[val]\n",
    "    y_vl = y_train[val]\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(\n",
    "        X_tr, y_tr, epochs=100, batch_size=32, validation_data=(X_vl, y_vl), verbose=True, \n",
    "        callbacks=[SpearmanRhoCallback(training_data=(X_tr, y_tr), validation_data=(X_vl, y_vl),\n",
    "                                       patience=5, model_name=f'best_model_batch{ind}.h5')]\n",
    "    )\n",
    "    all_predictions.append(model.predict(X_test))\n",
    "    \n",
    "model = create_model()\n",
    "model.fit(X_train, y_train, epochs=33, batch_size=32, verbose=False)\n",
    "all_predictions.append(model.predict(X_test))\n",
    "    \n",
    "kf = KFold(n_splits=5, random_state=2019, shuffle=True)\n",
    "for ind, (tr, val) in enumerate(kf.split(X_train)):\n",
    "    X_tr = X_train[tr]\n",
    "    y_tr = y_train[tr]\n",
    "    X_vl = X_train[val]\n",
    "    y_vl = y_train[val]\n",
    "    \n",
    "    model = MultiTaskElasticNet(alpha=0.001, random_state=42, l1_ratio=0.5)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    all_predictions.append(model.predict(X_test))\n",
    "    \n",
    "model = MultiTaskElasticNet(alpha=0.001, random_state=42, l1_ratio=0.5)\n",
    "model.fit(X_train, y_train)\n",
    "all_predictions.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.array([np.array([rankdata(c) for c in p.T]).T for p in all_predictions]).mean(axis=0)\n",
    "max_val = test_preds.max() + 1\n",
    "test_preds = test_preds/max_val + 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.590321</td>\n",
       "      <td>0.600280</td>\n",
       "      <td>0.844165</td>\n",
       "      <td>0.515374</td>\n",
       "      <td>0.499651</td>\n",
       "      <td>0.211391</td>\n",
       "      <td>0.752096</td>\n",
       "      <td>0.797869</td>\n",
       "      <td>0.824773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735674</td>\n",
       "      <td>0.328267</td>\n",
       "      <td>0.135570</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.320056</td>\n",
       "      <td>0.233403</td>\n",
       "      <td>0.095038</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.894130</td>\n",
       "      <td>0.605171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.280573</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.383473</td>\n",
       "      <td>0.456324</td>\n",
       "      <td>0.607093</td>\n",
       "      <td>0.500874</td>\n",
       "      <td>0.316737</td>\n",
       "      <td>0.438679</td>\n",
       "      <td>0.123515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079490</td>\n",
       "      <td>0.498777</td>\n",
       "      <td>0.226939</td>\n",
       "      <td>0.486723</td>\n",
       "      <td>0.351502</td>\n",
       "      <td>0.243361</td>\n",
       "      <td>0.954927</td>\n",
       "      <td>0.446017</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.188679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.451258</td>\n",
       "      <td>0.594689</td>\n",
       "      <td>0.313417</td>\n",
       "      <td>0.406883</td>\n",
       "      <td>0.780573</td>\n",
       "      <td>0.938330</td>\n",
       "      <td>0.467331</td>\n",
       "      <td>0.257338</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769217</td>\n",
       "      <td>0.284766</td>\n",
       "      <td>0.126660</td>\n",
       "      <td>0.448637</td>\n",
       "      <td>0.178197</td>\n",
       "      <td>0.115304</td>\n",
       "      <td>0.207372</td>\n",
       "      <td>0.160727</td>\n",
       "      <td>0.872467</td>\n",
       "      <td>0.482006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.234626</td>\n",
       "      <td>0.039483</td>\n",
       "      <td>0.377184</td>\n",
       "      <td>0.396576</td>\n",
       "      <td>0.579315</td>\n",
       "      <td>0.642907</td>\n",
       "      <td>0.317785</td>\n",
       "      <td>0.371768</td>\n",
       "      <td>0.766771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210867</td>\n",
       "      <td>0.817261</td>\n",
       "      <td>0.886618</td>\n",
       "      <td>0.690776</td>\n",
       "      <td>0.803983</td>\n",
       "      <td>0.887317</td>\n",
       "      <td>0.687806</td>\n",
       "      <td>0.735150</td>\n",
       "      <td>0.749301</td>\n",
       "      <td>0.156709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.976240</td>\n",
       "      <td>0.542802</td>\n",
       "      <td>0.736373</td>\n",
       "      <td>0.974668</td>\n",
       "      <td>0.517820</td>\n",
       "      <td>0.551013</td>\n",
       "      <td>0.891509</td>\n",
       "      <td>0.884696</td>\n",
       "      <td>0.798393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693047</td>\n",
       "      <td>0.450908</td>\n",
       "      <td>0.573375</td>\n",
       "      <td>0.697589</td>\n",
       "      <td>0.586303</td>\n",
       "      <td>0.381377</td>\n",
       "      <td>0.249301</td>\n",
       "      <td>0.825821</td>\n",
       "      <td>0.581237</td>\n",
       "      <td>0.530922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.590321                0.600280   \n",
       "1     46                             0.280573                0.416667   \n",
       "2     70                             0.451258                0.594689   \n",
       "3    132                             0.234626                0.039483   \n",
       "4    200                             0.976240                0.542802   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.844165                      0.515374   \n",
       "1                 0.383473                      0.456324   \n",
       "2                 0.313417                      0.406883   \n",
       "3                 0.377184                      0.396576   \n",
       "4                 0.736373                      0.974668   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.499651                               0.211391   \n",
       "1               0.607093                               0.500874   \n",
       "2               0.780573                               0.938330   \n",
       "3               0.579315                               0.642907   \n",
       "4               0.517820                               0.551013   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.752096                       0.797869   \n",
       "1                         0.316737                       0.438679   \n",
       "2                         0.467331                       0.257338   \n",
       "3                         0.317785                       0.371768   \n",
       "4                         0.891509                       0.884696   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.824773  ...               0.735674        0.328267   \n",
       "1               0.123515  ...               0.079490        0.498777   \n",
       "2               0.584906  ...               0.769217        0.284766   \n",
       "3               0.766771  ...               0.210867        0.817261   \n",
       "4               0.798393  ...               0.693047        0.450908   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.135570          0.250000          0.320056   \n",
       "1                     0.226939          0.486723          0.351502   \n",
       "2                     0.126660          0.448637          0.178197   \n",
       "3                     0.886618          0.690776          0.803983   \n",
       "4                     0.573375          0.697589          0.586303   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.233403                  0.095038               0.132600   \n",
       "1             0.243361                  0.954927               0.446017   \n",
       "2             0.115304                  0.207372               0.160727   \n",
       "3             0.887317                  0.687806               0.735150   \n",
       "4             0.381377                  0.249301               0.825821   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.894130             0.605171  \n",
       "1                        0.046296             0.188679  \n",
       "2                        0.872467             0.482006  \n",
       "3                        0.749301             0.156709  \n",
       "4                        0.581237             0.530922  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path_join(data_dir, 'sample_submission.csv'))\n",
    "submission[targets] = test_preds\n",
    "submission.to_csv(\"submission.csv\", index = False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
